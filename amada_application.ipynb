{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768c7740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_79466/41089160.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/usr/lib/python3/dist-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/lib/python3/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/lib/python3/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 461, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 450, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 357, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 652, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_79466/41089160.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/arrays/arrow/array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/home/students-aimssn/.local/lib/python3.10/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/usr/lib/python3/dist-packages/bottleneck/__init__.py\", line 2, in <module>\n",
      "    from .reduce import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students-aimssn/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
      "2025-12-09 01:16:18.924 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.071 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /usr/lib/python3/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-12-09 01:16:19.072 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.073 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.074 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.075 No runtime found, using MemoryCacheStorageManager\n",
      "2025-12-09 01:16:19.077 No runtime found, using MemoryCacheStorageManager\n",
      "2025-12-09 01:16:19.079 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.080 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.081 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.082 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.083 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.083 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.084 Session state does not function when running a script without `streamlit run`\n",
      "2025-12-09 01:16:19.084 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.085 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.086 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.087 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.215 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.216 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.218 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.219 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.235 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.263 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.263 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 01:16:19.266 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.271 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.272 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-12-09 01:16:19.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from requests import get\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "st.markdown(\"<h1 style='text-align: center; color: white;'>CoinAfrique Data Explorer</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Welcome to **CoinAfrique Data Explorer**, a user-friendly app for analyzing marketplace listings from [CoinAfrique](https://sn.coinafrique.com/).  \n",
    "With this app, you can:\n",
    "\n",
    "- **Scrape product data** across multiple pages automatically  \n",
    "- **Download cleaned datasets** directly in CSV format  \n",
    "- **Visualize trends and insights** with interactive charts  \n",
    "\n",
    "**Python libraries used:** `pandas`, `streamlit`, `requests`, `beautifulsoup4`, `matplotlib`, `seaborn`, `base64`  \n",
    "**Data source:** [CoinAfrique](https://sn.coinafrique.com/)\n",
    "\"\"\")\n",
    "\n",
    "# Background function\n",
    "def add_bg_from_local(image_file):\n",
    "    with open(image_file, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "    st.markdown(\n",
    "    f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-image: url(data:image/{\"jpg\"};base64,{encoded_string.decode()});\n",
    "        background-size: cover\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "# # Web scraping of Clothes-Shoes data on coinafrique\n",
    "@st.cache_data\n",
    "\n",
    "def convert_df(df):\n",
    "    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "    return df.to_csv().encode('utf-8')\n",
    "\n",
    "\n",
    "def load(dataframe, title, key, key1) :\n",
    "    # Créer 3 colonnes avec celle du milieu plus large\n",
    "    col1, col2, col3 = st.columns([1, 2, 1])\n",
    "    \n",
    "    with col2:\n",
    "        if st.button(title, key1):\n",
    "            st.subheader('Display data dimension')\n",
    "            st.write('Data dimension: ' + str(dataframe.shape[0]) + ' rows and ' + str(dataframe.shape[1]) + ' columns.')\n",
    "            st.dataframe(dataframe)\n",
    "\n",
    "            csv = convert_df(dataframe)\n",
    "\n",
    "            st.download_button(\n",
    "                label=\"Download data as CSV\",\n",
    "                data=csv,\n",
    "                file_name='Data.csv',\n",
    "                mime='text/csv',\n",
    "                key = key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def local_css(file_name):\n",
    "    with open(file_name) as f:\n",
    "        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "\n",
    "# Background function\n",
    "def add_bg_from_local(image_file):\n",
    "    with open(image_file, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "    st.markdown(\n",
    "    f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-image: url(data:image/{\"jpg\"};base64,{encoded_string.decode()});\n",
    "        background-size: cover\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "# Web scraping of Vehicles data on expat-dakar\n",
    "@st.cache_data\n",
    "\n",
    "def convert_df(df):\n",
    "    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "    return df.to_csv().encode('utf-8')\n",
    "\n",
    "\n",
    "\n",
    "def load(dataframe, title, key, key1) :\n",
    "    # Créer 3 colonnes avec celle du milieu plus large\n",
    "    col1, col2, col3 = st.columns([1, 2, 1])\n",
    "    \n",
    "    with col2:\n",
    "        if st.button(title, key1):\n",
    "            st.subheader('Display data dimension')\n",
    "            st.write('Data dimension: ' + str(dataframe.shape[0]) + ' rows and ' + str(dataframe.shape[1]) + ' columns.')\n",
    "            st.dataframe(dataframe)\n",
    "\n",
    "            csv = convert_df(dataframe)\n",
    "\n",
    "            st.download_button(\n",
    "                label=\"Download data as CSV\",\n",
    "                data=csv,\n",
    "                file_name='Data.csv',\n",
    "                mime='text/csv',\n",
    "                key = key)\n",
    "            \n",
    "            \n",
    "def local_css(file_name):\n",
    "    with open(file_name) as f:\n",
    "        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# Fonction for web scraping vetements-homme\n",
    "def load_vetements_hommes(mul_page):\n",
    "    data = []\n",
    "    # create a empty dataframe df\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/vetements-homme?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_clothes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_clothes':type_clothes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"vetements_hommes_clean.csv\", index = False)\n",
    "        \n",
    "    return df \n",
    "\n",
    "\n",
    "# Fonction for web scraping chaussures-homme\n",
    "def load_chaussures_hommes(mul_page):\n",
    "    data = []\n",
    "    # create a empty dataframe df\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/chaussures-homme?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_shoes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_shoes':type_shoes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"chaussures_hommes_clean.csv\", index = False)\n",
    "    return df\n",
    "\n",
    "# Fonction for web scraping vetements-enfants\n",
    "def load_vetements_enfants(mul_page):\n",
    "    # create a empty dataframe df\n",
    "    data = []\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/vetements-enfants?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_clothes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_clothes':type_clothes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"vetements_enfants_clean.csv\", index = False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Fonction for web scraping chaussures-enfants\n",
    "def load_chaussures_enfants(mul_page):\n",
    "    # create a empty dataframe df\n",
    "    data = []\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/chaussures-enfants?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_shoes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_shoes':type_shoes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"chaussures_enfants_clean.csv\", index = False)\n",
    "    return df \n",
    "\n",
    "\n",
    "st.sidebar.header('User Input Features')\n",
    "Pages = st.sidebar.selectbox('Pages indexes', list([int(p) for p in np.arange(2, 600)]))\n",
    "Choices = st.sidebar.selectbox('Options', ['Scrape data using Wed Scraper','Scrape data using beautifulSoup', 'Download scraped data', 'Dashbord of the data', 'Evaluate the App'])\n",
    "\n",
    "\n",
    "add_bg_from_local('img_fil2.jpg') \n",
    "\n",
    "local_css('style.css')\n",
    "\n",
    "if Choices=='Scrape data using Wed Scraper':\n",
    "    # load the data\n",
    "    load(pd.read_csv('data/vetements_hommes.csv'), 'vetements_hommes', '1','101')\n",
    "    load(pd.read_csv('data/vetements_enfants.csv'), 'vetements_enfants', '2', '102')\n",
    "    load(pd.read_csv('data/chaussures_hommes.csv'), 'chaussures_hommes', '3', '103')\n",
    "    load(pd.read_csv('data/chaussures_enfants.csv'), 'chaussures_enfants', '4', '104')\n",
    "\n",
    "elif Choices=='Scrape data using beautifulSoup':\n",
    "    vetements_hommes_data_mul_pag=load_vetements_hommes(Pages)\n",
    "    chaussures_hommes_data_mul_pag=load_chaussures_hommes(Pages)\n",
    "    vetements_enfants_data_mul_pag=load_vetements_enfants(Pages)\n",
    "    chaussures_enfants_data_mul_pag=load_chaussures_enfants(Pages)\n",
    "    \n",
    "    load(vetements_hommes_data_mul_pag, 'vetements hommes data', '1', '101')\n",
    "    load(chaussures_hommes_data_mul_pag, 'chaussures hommes data', '2', '102')\n",
    "    load(vetements_enfants_data_mul_pag, 'vetements enfants data', '3', '103')\n",
    "    load(chaussures_enfants_data_mul_pag, 'chaussures enfants data', '4', '104')\n",
    "\n",
    "    \n",
    "elif Choices == 'Download scraped data': \n",
    "    vetements_hommes = pd.read_csv('vetements_hommes_clean.csv')\n",
    "    chaussures_hommes = pd.read_csv('chaussures_hommes_clean.csv')\n",
    "    vetements_enfants = pd.read_csv('vetements_enfants_clean.csv')\n",
    "    chaussures_enfants = pd.read_csv('chaussures_enfants_clean.csv')\n",
    "    \n",
    "    load(vetements_hommes, 'vetements hommes data', '1', '101')\n",
    "    load(chaussures_hommes, 'chaussures hommes data', '2', '102')\n",
    "    load(vetements_enfants, 'vetements enfants data', '3', '103')\n",
    "    load(chaussures_enfants, 'chaussures enfants data', '4', '104')\n",
    "    \n",
    "\n",
    "elif  Choices == 'Dashbord of the data':\n",
    "    data1 = pd.read_csv('vetements_hommes_clean.csv')\n",
    "    data2 = pd.read_csv('chaussures_hommes_clean.csv')\n",
    "    data3 = pd.read_csv('vetements_enfants_clean.csv')\n",
    "    data4 = pd.read_csv('chaussures_enfants_clean.csv')\n",
    "    \n",
    "    st.subheader(\" Dashboard — Analysis of the 4 categories\")\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Top 5 most common articles\")\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=data1['type_clothes'].value_counts()[:5].values,\n",
    "                    y=data1['type_clothes'].value_counts()[:5].index)\n",
    "        plt.title(\"Top 5 men's clothing items\")\n",
    "        plt.xlabel(\"Nombre\")\n",
    "        st.pyplot(fig1)\n",
    "\n",
    "    with col2:\n",
    "        fig2 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=data2['type_shoes'].value_counts()[:5].values,\n",
    "                    y=data2['type_shoes'].value_counts()[:5].index)\n",
    "        plt.title(\"Top 5 men's shoes\")\n",
    "        plt.xlabel(\"Number\")\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Average price per item type\")\n",
    "\n",
    "    col3, col4 = st.columns(2)\n",
    "\n",
    "    with col3:\n",
    "        fig3 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(data=data1, x=\"type_clothes\", y=\"price\", errorbar=None)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(\"Average price — Men's clothing\")\n",
    "        st.pyplot(fig3)\n",
    "\n",
    "    with col4:\n",
    "        fig4 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(data=data2, x=\"type_shoes\", y=\"price\", errorbar=None)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(\"Average price — Men's shoes\")\n",
    "        st.pyplot(fig4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Award ceremony\")\n",
    "\n",
    "    col5, col6 = st.columns(2)\n",
    "\n",
    "    with col5:\n",
    "        fig5 = plt.figure(figsize=(10,6))\n",
    "        sns.histplot(data1[\"price\"], kde=True)\n",
    "        plt.title(\"Award Ceremony — Men's Clothing\")\n",
    "        st.pyplot(fig5)\n",
    "\n",
    "    with col6:\n",
    "        fig6 = plt.figure(figsize=(10,6))\n",
    "        sns.histplot(data2[\"price\"], kde=True)\n",
    "        plt.title(\"Award ceremony — Men's shoes\")\n",
    "        st.pyplot(fig6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Analysis — Children\")\n",
    "\n",
    "    col7, col8 = st.columns(2)\n",
    "\n",
    "    with col7:\n",
    "        fig7 = plt.figure(figsize=(10,6))\n",
    "\n",
    "        top5_clothes_children = data3['type_clothes'].value_counts().head(5)\n",
    "\n",
    "        plt.pie(\n",
    "            top5_clothes_children.values,\n",
    "            labels=top5_clothes_children.index,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=140\n",
    "        )\n",
    "    plt.title(\"Top 5 children's clothing items\")\n",
    "    plt.tight_layout()\n",
    "    st.pyplot(fig7)\n",
    "    with col8:\n",
    "        fig8 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=data4['type_shoes'].value_counts()[:5].values,\n",
    "                    y=data4['type_shoes'].value_counts()[:5].index)\n",
    "        plt.title(\"Top 5 children's shoes\")\n",
    "        st.pyplot(fig8)\n",
    "\n",
    "\n",
    "else :\n",
    "\n",
    "    st.markdown(\"<h3 style='text-align: center;'>Give your Feedback</h3>\", unsafe_allow_html=True)\n",
    "\n",
    "    # centrer les deux boutons\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        if st.button(\"Kobo Evaluation Form\"):\n",
    "            st.markdown(\n",
    "                '<meta http-equiv=\"refresh\" content=\"0; url=https://ee.kobotoolbox.org/x/4ep3EmZb\">',\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "\n",
    "    with col2:\n",
    "        if st.button(\"Google Forms Evaluation\"):\n",
    "            st.markdown(\n",
    "                '<meta http-equiv=\"refresh\" content=\"0; url=https://forms.gle/gTg77pn8rnFrfoEd6\">',\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92bce26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier amada_app.py créé avec succès !\n"
     ]
    }
   ],
   "source": [
    "with open(\"amada_app.py\", \"w\") as f:\n",
    "    f.write('''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from requests import get\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "st.markdown(\"<h1 style='text-align: center; color: white;'>CoinAfrique Data Explorer</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "Welcome to **CoinAfrique Data Explorer**, a user-friendly app for analyzing marketplace listings from [CoinAfrique](https://sn.coinafrique.com/).  \n",
    "With this app, you can:\n",
    "\n",
    "- **Scrape product data** across multiple pages automatically  \n",
    "- **Download cleaned datasets** directly in CSV format  \n",
    "- **Visualize trends and insights** with interactive charts  \n",
    "\n",
    "**Python libraries used:** `pandas`, `streamlit`, `requests`, `beautifulsoup4`, `matplotlib`, `seaborn`, `base64`  \n",
    "**Data source:** [CoinAfrique](https://sn.coinafrique.com/)\n",
    "\"\"\")\n",
    "\n",
    "# Background function\n",
    "def add_bg_from_local(image_file):\n",
    "    with open(image_file, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "    st.markdown(\n",
    "    f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-image: url(data:image/{\"jpg\"};base64,{encoded_string.decode()});\n",
    "        background-size: cover\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "# Web scraping of Clothes-Shoes data on coinafrique\n",
    "@st.cache_data\n",
    "\n",
    "def convert_df(df):\n",
    "    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "    return df.to_csv().encode('utf-8')\n",
    "\n",
    "\n",
    "def load(dataframe, title, key, key1) :\n",
    "    # Créer 3 colonnes avec celle du milieu plus large\n",
    "    col1, col2, col3 = st.columns([1, 2, 1])\n",
    "    \n",
    "    with col2:\n",
    "        if st.button(title, key1):\n",
    "            st.subheader('Display data dimension')\n",
    "            st.write('Data dimension: ' + str(dataframe.shape[0]) + ' rows and ' + str(dataframe.shape[1]) + ' columns.')\n",
    "            st.dataframe(dataframe)\n",
    "\n",
    "            csv = convert_df(dataframe)\n",
    "\n",
    "            st.download_button(\n",
    "                label=\"Download data as CSV\",\n",
    "                data=csv,\n",
    "                file_name='Data.csv',\n",
    "                mime='text/csv',\n",
    "                key = key)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def local_css(file_name):\n",
    "    with open(file_name) as f:\n",
    "        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "\n",
    "# Background function\n",
    "def add_bg_from_local(image_file):\n",
    "    with open(image_file, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "    st.markdown(\n",
    "    f\"\"\"\n",
    "    <style>\n",
    "    .stApp {{\n",
    "        background-image: url(data:image/{\"jpg\"};base64,{encoded_string.decode()});\n",
    "        background-size: cover\n",
    "    }}\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "# Web scraping of Vehicles data on expat-dakar\n",
    "@st.cache_data\n",
    "\n",
    "def convert_df(df):\n",
    "    # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "    return df.to_csv().encode('utf-8')\n",
    "\n",
    "\n",
    "\n",
    "def load(dataframe, title, key, key1) :\n",
    "    # Créer 3 colonnes avec celle du milieu plus large\n",
    "    col1, col2, col3 = st.columns([1, 2, 1])\n",
    "    \n",
    "    with col2:\n",
    "        if st.button(title, key1):\n",
    "            st.subheader('Display data dimension')\n",
    "            st.write('Data dimension: ' + str(dataframe.shape[0]) + ' rows and ' + str(dataframe.shape[1]) + ' columns.')\n",
    "            st.dataframe(dataframe)\n",
    "\n",
    "            csv = convert_df(dataframe)\n",
    "\n",
    "            st.download_button(\n",
    "                label=\"Download data as CSV\",\n",
    "                data=csv,\n",
    "                file_name='Data.csv',\n",
    "                mime='text/csv',\n",
    "                key = key)\n",
    "            \n",
    "            \n",
    "def local_css(file_name):\n",
    "    with open(file_name) as f:\n",
    "        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# Fonction for web scraping vetements-homme\n",
    "def load_vetements_hommes(mul_page):\n",
    "    data = []\n",
    "    # create a empty dataframe df\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/vetements-homme?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_clothes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_clothes':type_clothes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"vetements_hommes_clean.csv\", index = False)\n",
    "        \n",
    "    return df \n",
    "\n",
    "\n",
    "# Fonction for web scraping chaussures-homme\n",
    "def load_chaussures_hommes(mul_page):\n",
    "    data = []\n",
    "    # create a empty dataframe df\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/chaussures-homme?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_shoes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_shoes':type_shoes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"chaussures_hommes_clean.csv\", index = False)\n",
    "    return df\n",
    "\n",
    "# Fonction for web scraping vetements-enfants\n",
    "def load_vetements_enfants(mul_page):\n",
    "    # create a empty dataframe df\n",
    "    data = []\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/vetements-enfants?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_clothes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_clothes':type_clothes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"vetements_enfants_clean.csv\", index = False)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Fonction for web scraping chaussures-enfants\n",
    "def load_chaussures_enfants(mul_page):\n",
    "    # create a empty dataframe df\n",
    "    data = []\n",
    "    df = pd.DataFrame()\n",
    "    # loop over pages indexes\n",
    "    for p in range(1, int(mul_page)+1):  \n",
    "        url = f'https://sn.coinafrique.com/categorie/chaussures-enfants?page={p}'\n",
    "        res = get(url)\n",
    "        soup = bs(res.content, 'html.parser')\n",
    "        containers = soup.find_all('div','col s6 m4 l3')\n",
    "        for container in containers:\n",
    "            try:\n",
    "                type_shoes = container.find('p', 'ad__card-description').text\n",
    "                price = container.find('p', 'ad__card-price').text\n",
    "                adress = container.find('p', 'ad__card-location').span.text\n",
    "                image_link = container.find('img','ad__card-img')['src'] \n",
    "            \n",
    "                dic = {\n",
    "                'type_shoes':type_shoes,\n",
    "                'price':price,\n",
    "                'adress':adress,\n",
    "                'image_link':image_link\n",
    "                      }\n",
    "                data.append(dic)\n",
    "            except: \n",
    "                pass\n",
    "        \n",
    "        DF = pd.DataFrame(data)\n",
    "        df= pd.concat([df, DF], axis =0).reset_index(drop = True)\n",
    "        \n",
    "        # Clean data\n",
    "        df_clean = df.drop_duplicates()\n",
    "        df_clean = df_clean[df_clean['price'] != 'Prix sur demande']\n",
    "        df_clean['price'] = df_clean['price'].str.replace('CFA', '')\n",
    "        df_clean['price'] = df_clean['price'].str.replace(' ', '')\n",
    "        df_clean['price'] = pd.to_numeric(df_clean['price'])\n",
    "        df_clean.to_csv(\"chaussures_enfants_clean.csv\", index = False)\n",
    "    return df \n",
    "\n",
    "\n",
    "st.sidebar.header('User Input Features')\n",
    "Pages = st.sidebar.selectbox('Pages indexes', list([int(p) for p in np.arange(2, 600)]))\n",
    "Choices = st.sidebar.selectbox('Options', ['Scrape data using Wed Scraper','Scrape data using beautifulSoup', 'Download scraped data', 'Dashbord of the data', 'Evaluate the App'])\n",
    "\n",
    "\n",
    "add_bg_from_local('img_fil2.jpg') \n",
    "\n",
    "local_css('style.css') \n",
    "\n",
    "if Choices=='Scrape data using Wed Scraper':\n",
    "    # load the data\n",
    "    load(pd.read_csv('data/vetements_hommes.csv'), 'vetements_hommes', '1','101')\n",
    "    load(pd.read_csv('data/vetements_enfants.csv'), 'vetements_enfants', '2', '102')\n",
    "    load(pd.read_csv('data/chaussures_hommes.csv'), 'chaussures_hommes', '3', '103')\n",
    "    load(pd.read_csv('data/chaussures_enfants.csv'), 'chaussures_enfants', '4', '104')\n",
    "\n",
    "\n",
    "elif Choices=='Scrape data using beautifulSoup':\n",
    "    vetements_hommes_data_mul_pag=load_vetements_hommes(Pages)\n",
    "    chaussures_hommes_data_mul_pag=load_chaussures_hommes(Pages)\n",
    "    vetements_enfants_data_mul_pag=load_vetements_enfants(Pages)\n",
    "    chaussures_enfants_data_mul_pag=load_chaussures_enfants(Pages)\n",
    "    \n",
    "    load(vetements_hommes_data_mul_pag, 'vetements hommes data', '1', '101')\n",
    "    load(chaussures_hommes_data_mul_pag, 'chaussures hommes data', '2', '102')\n",
    "    load(vetements_enfants_data_mul_pag, 'vetements enfants data', '3', '103')\n",
    "    load(chaussures_enfants_data_mul_pag, 'chaussures enfants data', '4', '104')\n",
    "\n",
    "    \n",
    "elif Choices == 'Download scraped data': \n",
    "    vetements_hommes = pd.read_csv('vetements_hommes_clean.csv')\n",
    "    chaussures_hommes = pd.read_csv('chaussures_hommes_clean.csv')\n",
    "    vetements_enfants = pd.read_csv('vetements_enfants_clean.csv')\n",
    "    chaussures_enfants = pd.read_csv('chaussures_enfants_clean.csv')\n",
    "    \n",
    "    load(vetements_hommes, 'vetements hommes data', '1', '101')\n",
    "    load(chaussures_hommes, 'chaussures hommes data', '2', '102')\n",
    "    load(vetements_enfants, 'vetements enfants data', '3', '103')\n",
    "    load(chaussures_enfants, 'chaussures enfants data', '4', '104')\n",
    "    \n",
    "\n",
    "elif  Choices == 'Dashbord of the data':\n",
    "    data1 = pd.read_csv('vetements_hommes_clean.csv')\n",
    "    data2 = pd.read_csv('chaussures_hommes_clean.csv')\n",
    "    data3 = pd.read_csv('vetements_enfants_clean.csv')\n",
    "    data4 = pd.read_csv('chaussures_enfants_clean.csv')\n",
    "    \n",
    "    st.subheader(\" Dashboard — Analysis of the 4 categories\")\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Top 5 most common articles\")\n",
    "\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        fig1 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=data1['type_clothes'].value_counts()[:5].values,\n",
    "                    y=data1['type_clothes'].value_counts()[:5].index)\n",
    "        plt.title(\"Top 5 men's clothing items\")\n",
    "        plt.xlabel(\"Nombre\")\n",
    "        st.pyplot(fig1)\n",
    "\n",
    "    with col2:\n",
    "        fig2 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=data2['type_shoes'].value_counts()[:5].values,\n",
    "                    y=data2['type_shoes'].value_counts()[:5].index)\n",
    "        plt.title(\"Top 5 men's shoes\")\n",
    "        plt.xlabel(\"Number\")\n",
    "        st.pyplot(fig2)\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Average price per item type\")\n",
    "\n",
    "    col3, col4 = st.columns(2)\n",
    "\n",
    "    with col3:\n",
    "        fig3 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(data=data1, x=\"type_clothes\", y=\"price\", errorbar=None)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(\"Average price — Men's clothing\")\n",
    "        st.pyplot(fig3)\n",
    "\n",
    "    with col4:\n",
    "        fig4 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(data=data2, x=\"type_shoes\", y=\"price\", errorbar=None)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(\"Average price — Men's shoes\")\n",
    "        st.pyplot(fig4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Award ceremony\")\n",
    "\n",
    "    col5, col6 = st.columns(2)\n",
    "\n",
    "    with col5:\n",
    "        fig5 = plt.figure(figsize=(10,6))\n",
    "        sns.histplot(data1[\"price\"], kde=True)\n",
    "        plt.title(\"Award Ceremony — Men's Clothing\")\n",
    "        st.pyplot(fig5)\n",
    "\n",
    "    with col6:\n",
    "        fig6 = plt.figure(figsize=(10,6))\n",
    "        sns.histplot(data2[\"price\"], kde=True)\n",
    "        plt.title(\"Award ceremony — Men's shoes\")\n",
    "        st.pyplot(fig6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    st.markdown(\"###  Analysis — Children\")\n",
    "\n",
    "    col7, col8 = st.columns(2)\n",
    "\n",
    "    with col7:\n",
    "        fig7 = plt.figure(figsize=(10,6))\n",
    "\n",
    "        top5_clothes_children = data3['type_clothes'].value_counts().head(5)\n",
    "\n",
    "        plt.pie(\n",
    "            top5_clothes_children.values,\n",
    "            labels=top5_clothes_children.index,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=140\n",
    "        )\n",
    "    plt.title(\"Top 5 children's clothing items\")\n",
    "    plt.tight_layout()\n",
    "    st.pyplot(fig7)\n",
    "    with col8:\n",
    "        fig8 = plt.figure(figsize=(10,6))\n",
    "        sns.barplot(x=data4['type_shoes'].value_counts()[:5].values,\n",
    "                    y=data4['type_shoes'].value_counts()[:5].index)\n",
    "        plt.title(\"Top 5 children's shoes\")\n",
    "        st.pyplot(fig8)\n",
    "\n",
    "\n",
    "else :\n",
    "\n",
    "    st.markdown(\"<h3 style='text-align: center;'>Give your Feedback</h3>\", unsafe_allow_html=True)\n",
    "\n",
    "    # centrer les deux boutons\n",
    "    col1, col2 = st.columns(2)\n",
    "\n",
    "    with col1:\n",
    "        if st.button(\"Kobo Evaluation Form\"):\n",
    "            st.markdown(\n",
    "                '<meta http-equiv=\"refresh\" content=\"0; url=https://ee.kobotoolbox.org/x/4ep3EmZb\">',\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "\n",
    "    with col2:\n",
    "        if st.button(\"Google Forms Evaluation\"):\n",
    "            st.markdown(\n",
    "                '<meta http-equiv=\"refresh\" content=\"0; url=https://forms.gle/gTg77pn8rnFrfoEd6\">',\n",
    "                unsafe_allow_html=True\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "''')\n",
    "\n",
    "print(\"Fichier amada_app.py créé avec succès !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9fa7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
